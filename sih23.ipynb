{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nimage_folder_path = '/kaggle/input/segmented-medicinal-leaf-images/Segmented Medicinal Leaf Images'\n# Load and Preprocess Images\nwidth = 64  # Set the desired image width for resizing\nheight = 64  # Set the desired image height for resizing\n\nX = []  # Image data\ny = []  # Labels\n\n# Loop through subfolders (classes)\nfor class_name in os.listdir(image_folder_path):\n    class_dir = os.path.join(image_folder_path, class_name)\n    \n    # Loop through images in each class\n    for image_name in os.listdir(class_dir):\n        image_path = os.path.join(class_dir, image_name)\n        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n        image = cv2.resize(image, (width, height))  # Resize to a fixed size\n        X.append(image.flatten())  # Convert to a 1D feature vector\n        y.append(class_name)  # Label is the subfolder (class) name\n\n# Data Splitting\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Model Building\nk_neighbors = 3  # You can adjust the number of neighbors as needed\nknn_model = KNeighborsClassifier(n_neighbors=k_neighbors)\nknn_model.fit(X_train, y_train)\n\n# Model Evaluation\ny_pred = knn_model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Classification Report:\\n{report}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-05T16:21:32.555584Z","iopub.execute_input":"2023-09-05T16:21:32.556102Z","iopub.status.idle":"2023-09-05T16:21:59.440657Z","shell.execute_reply.started":"2023-09-05T16:21:32.556054Z","shell.execute_reply":"2023-09-05T16:21:59.439330Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Accuracy: 0.6348773841961853\nClassification Report:\n                                              precision    recall  f1-score   support\n\n                     Alpinia Galanga (Rasna)       0.50      1.00      0.67         5\n            Amaranthus Viridis (Arive-Dantu)       0.41      0.73      0.52        22\n        Artocarpus Heterophyllus (Jackfruit)       0.45      0.91      0.61        11\n                   Azadirachta Indica (Neem)       1.00      0.56      0.71         9\n                       Basella Alba (Basale)       0.52      0.81      0.63        16\n            Brassica Juncea (Indian Mustard)       0.50      0.38      0.43         8\n                  Carissa Carandas (Karanda)       0.53      0.83      0.65        12\n                        Citrus Limon (Lemon)       0.38      0.45      0.42        11\n             Ficus Auriculata (Roxburgh fig)       0.50      0.55      0.52        11\n               Ficus Religiosa (Peepal Tree)       1.00      0.73      0.85        15\n                      Hibiscus Rosa-sinensis       0.80      0.80      0.80         5\n                          Jasminum (Jasmine)       0.92      0.73      0.81        15\n                    Mangifera Indica (Mango)       0.73      0.57      0.64        14\n                               Mentha (Mint)       0.80      0.59      0.68        27\n                Moringa Oleifera (Drumstick)       0.74      0.70      0.72        20\nMuntingia Calabura (Jamaica Cherry-Gasagase)       0.90      0.69      0.78        13\n                    Murraya Koenigii (Curry)       0.60      0.38      0.46         8\n                  Nerium Oleander (Oleander)       0.58      0.88      0.70         8\n         Nyctanthes Arbor-tristis (Parijata)       1.00      0.89      0.94         9\n                  Ocimum Tenuiflorum (Tulsi)       0.50      0.11      0.18         9\n                         Piper Betle (Betel)       1.00      0.40      0.57        10\n      Plectranthus Amboinicus (Mexican Mint)       0.64      1.00      0.78         7\n             Pongamia Pinnata (Indian Beech)       1.00      0.58      0.74        12\n                     Psidium Guajava (Guava)       0.71      0.94      0.81        16\n               Punica Granatum (Pomegranate)       0.47      0.75      0.58        12\n                 Santalum Album (Sandalwood)       0.56      0.36      0.43        14\n                     Syzygium Cumini (Jamun)       0.67      0.43      0.52        14\n                Syzygium Jambos (Rose Apple)       1.00      0.64      0.78        14\n  Tabernaemontana Divaricata (Crape Jasmine)       0.57      0.31      0.40        13\n       Trigonella Foenum-graecum (Fenugreek)       0.40      0.29      0.33         7\n\n                                    accuracy                           0.63       367\n                                   macro avg       0.68      0.63      0.62       367\n                                weighted avg       0.69      0.63      0.63       367\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\n# Set the path to your dataset folder on Kaggle\nimage_folder_path = '/kaggle/input/segmented-medicinal-leaf-images/Segmented Medicinal Leaf Images'\n\n# Set the number of random images you want to select\nnum_random_images = 2\n\n# Initialize a list to store the paths of the selected images\nselected_image_paths = []\n\n# Loop through subfolders (classes)\nfor class_name in os.listdir(image_folder_path):\n    class_dir = os.path.join(image_folder_path, class_name)\n    \n    # Get a list of image file names in the class directory\n    image_files = os.listdir(class_dir)\n    \n    # Randomly select images from the class\n    random_images = random.sample(image_files, num_random_images)\n    \n    # Create the full paths to the selected images\n    selected_image_paths.extend([os.path.join(class_dir, img) for img in random_images])\n\n# Define a function to visualize images with annotations\ndef visualize_image_with_annotations(image_path, annotations):\n    # Load the image\n    img = cv2.imread(image_path)\n    \n    # Create a figure and axis\n    fig, ax = plt.subplots()\n    \n    # Display the image\n    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    \n    # Add annotations to the image\n    for annotation in annotations:\n        ax.add_patch(annotation)\n    \n    # Add labels to annotations\n    for i, annotation in enumerate(annotations):\n        x, y = annotation.get_xy()\n        ax.text(x, y, f\"Annotation {i + 1}\", fontsize=12, color='white')\n    \n    # Remove axis labels\n    ax.axis('off')\n    \n    # Show the image with annotations\n    plt.show()\n\n# Display the selected random images with annotations (e.g., rectangles)\nfor img_path in selected_image_paths:\n    # Generate random annotations (e.g., rectangles) for demonstration purposes\n    annotations = [\n        patches.Rectangle((10, 10), 50, 50, linewidth=2, edgecolor='r', facecolor='none'),\n        patches.Rectangle((80, 80), 30, 30, linewidth=2, edgecolor='b', facecolor='none')\n    ]\n    \n    # Visualize the image with annotations\n    visualize_image_with_annotations(img_path, annotations)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom PIL import Image\nimport io\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\n# Define a function to preprocess an uploaded image\ndef preprocess_uploaded_image(uploaded_image):\n    # Convert the uploaded image to grayscale\n    img_gray = cv2.cvtColor(np.array(uploaded_image), cv2.COLOR_RGB2GRAY)\n    # Resize the image to match the model's input size (64x64)\n    img_resized = cv2.resize(img_gray, (64, 64))\n    # Flatten the image into a 1D feature vector\n    img_flattened = img_resized.flatten()\n    return img_flattened\n\n# Define a function to make predictions using the KNN model\ndef predict_with_knn(image_data):\n    return knn_model.predict([image_data])[0]\n\n# Create an upload button for image selection\nupload_button = widgets.FileUpload(\n    accept='.jpg, .jpeg, .png',  # Specify accepted file types\n    multiple=False,  # Allow only a single file to be uploaded\n    description='Upload an Image'\n)\n\n# Create an output widget for displaying predictions\noutput = widgets.Output()\n\n# Flag to track if an image has been uploaded\nimage_uploaded = False\n\n# Define an event handler for the upload button\ndef on_upload_button_click(change):\n    global image_uploaded\n    if upload_button.value and not image_uploaded:\n        uploaded_image = Image.open(io.BytesIO(upload_button.value[0]['content']))\n        preprocessed_image = preprocess_uploaded_image(uploaded_image)\n        prediction = predict_with_knn(preprocessed_image)\n        \n        with output:\n            plt.gcf().clear()  # Clear the previous plot\n            plt.imshow(uploaded_image)\n            plt.axis('off')\n            plt.title(f'Predicted Class: {prediction}')\n            plt.show()\n        \n        # Disable the upload button after an image is uploaded\n        upload_button.disabled = True\n        image_uploaded = True\n\n# Attach the event handler to the upload button\nupload_button.observe(on_upload_button_click, names='value')\n\n# Create a VBox layout to arrange widgets vertically\nui = widgets.VBox([upload_button, output])\n\n# Display the user interface\ndisplay(ui)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T16:30:22.906893Z","iopub.execute_input":"2023-09-05T16:30:22.907410Z","iopub.status.idle":"2023-09-05T16:30:22.935983Z","shell.execute_reply.started":"2023-09-05T16:30:22.907371Z","shell.execute_reply":"2023-09-05T16:30:22.934695Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(FileUpload(value={}, accept='.jpg, .jpeg, .png', description='Upload an Image'), Output()))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a0e70fe05b44978c18295d3dab5c91"}},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Step 1: Load and Preprocess Images\nimage_folder_path = '/kaggle/input/segmented-medicinal-leaf-images/Segmented Medicinal Leaf Images'\nwidth = 64\nheight = 64\n\nX = []\ny = []\n\nfor class_name in os.listdir(image_folder_path):\n    class_dir = os.path.join(image_folder_path, class_name)\n    \n    for image_name in os.listdir(class_dir):\n        image_path = os.path.join(class_dir, image_name)\n        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        image = cv2.resize(image, (width, height))\n        X.append(image.flatten())\n        y.append(class_name)\n\n# Step 2: Data Splitting\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 3: Model Building with Hyperparameter Tuning\nparam_grid = {\n    'n_estimators': [50, 100, 150],          # Number of trees in the forest\n    'max_depth': [None, 10, 20, 30],        # Maximum depth of the trees\n    'min_samples_split': [2, 5, 10],        # Minimum samples required to split an internal node\n    'min_samples_leaf': [1, 2, 4],          # Minimum samples required for a leaf node\n    'max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider for the best split\n}\n\n# Create a Random Forest classifier\nrandom_forest_model = RandomForestClassifier(random_state=42)\n\n# Perform Grid Search for hyperparameter tuning\ngrid_search = GridSearchCV(random_forest_model, param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)\n\n# Get the best hyperparameters\nbest_params = grid_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)\n\n# Use the best hyperparameters to build the final model\nrandom_forest_model = RandomForestClassifier(\n    n_estimators=best_params['n_estimators'],\n    max_depth=best_params['max_depth'],\n    min_samples_split=best_params['min_samples_split'],\n    min_samples_leaf=best_params['min_samples_leaf'],\n    max_features='sqrt',\n    random_state=42\n)\n\nrandom_forest_model.fit(X_train, y_train)\n\n# Step 4: Model Evaluation\ny_pred = random_forest_model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Classification Report:\\n{report}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-05T16:57:53.878415Z","iopub.execute_input":"2023-09-05T16:57:53.878882Z","iopub.status.idle":"2023-09-05T16:58:27.443746Z","shell.execute_reply.started":"2023-09-05T16:57:53.878843Z","shell.execute_reply":"2023-09-05T16:58:27.441150Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.2s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.2s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.3s\n[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.2s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   2.9s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.0s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.6s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"[CV] END max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.6s\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n  warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Perform Grid Search for hyperparameter tuning\u001b[39;00m\n\u001b[1;32m     42\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(random_forest_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     46\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}